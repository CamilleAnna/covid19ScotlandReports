---
title: 'Briefing for C19AG: Comparison of doubling times'
subtitle: 'NOT FOR DISTRIBUTION'
author: "COVID-19 Epidemic Response Unit, University of Edinburgh"
date: "02/04/2020"
output: word_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

setwd('/Users/s1687811/Desktop/covid19/AG_briefing/')

today<- Sys.Date() - 1
its = 1000
set.seed(as.numeric(today))

source('Dt_sourced.R')


# LOADING DATA
d.uk<- 
  read_excel(paste0('./', today, '/UK_data_', today, '.xlsx'), sheet = 1) %>%
  mutate(date = as.Date(date)) %>%
  as.data.frame()

pops.shb<- read_excel('popsizes_grouped.xlsx', sheet = 1) %>% as.data.frame()
pops.uk<- read_excel('popsizes_grouped.xlsx', sheet = 2) %>% as.data.frame()

d.cases<-
  read_excel(paste0('./', today, '/SARS-Cov-2-Scotland_all_', today,'_reviewed.xlsx'), sheet = 4) %>%
  rename(date = `...1`) %>%
  mutate(date = as.Date(date)) %>%
  as.data.frame()

d.death<-
  read_excel(paste0('./', today, '/SARS-Cov-2-Scotland_all_', today,'_reviewed.xlsx'), sheet = 1) %>%
  mutate(Date = as.Date(Date)) %>%
  rename(date = Date,
         cumNumCases = Deaths_Cum) %>% # ! ambiguous var naming, because of constraint of sim function. But it is indeed cumulative number of DEATHS
  select(date, cumNumCases) %>%
  as.data.frame()


Td.report<- data.frame(variable = character(), Td.obs = numeric(), ci.low = numeric(), ci.upp = numeric(), t1 = character(), t2 = character())


```


```{r DEATHS}
t2<- tail(tail(d.death$date, 8), 1)
t1<- head(tail(d.death$date, 8), 1)

t1.f1 = t1
t2.f1 = t2

# Dt & CI computation
d.death.sim<- sim.epi(d.death, its = its, plotsim = FALSE) # Simulate poisson error

d.death.sim.2<- # format data with appended simulations to feed in compute.td() function
  d.death.sim %>%
  select(-date, -cumNumCases) %>%
  mutate_all(~ cumsum(.)) %>%
  rename(cumNumCases = numNewCases) %>%
  cbind(date = d.death.sim$date) %>%
  select(c(ncol(.), seq(1, ncol(.)-1)))

d.death.sim.2.list<- # Transform into a list to sapply compute.td.m1.v2() on each dataset
  d.death.sim.2 %>%
  select(-date) %>%
  as.list()

Tds.death<- sapply(d.death.sim.2.list, Td.lapply, dates = d.death.sim.2$date, t1 = t1, t2 = t2)

# Observed and bootstrap distribution of Tds
Td.death.obs<- as.numeric(Tds.death['cumNumCases'])
Td.death.bootstrap<- as.numeric(Tds.death[-which(names(Tds.death) == 'cumNumCases')])
Td.death.bootstrap<- Td.death.bootstrap[!is.na(Td.death.bootstrap == TRUE)] # NAs come from cases where there were still zero cases observed at t1 in a simulated dataset. Normal to happen when still very low number of cases observed. Becomes less of a problem as number of cases rise.

# Get CI from distribution of Td
ci.death.low<- round(quantile(Td.death.bootstrap, c(0.05), method = 6), 1)[[1]]
ci.death.upp<- round(quantile(Td.death.bootstrap, c(0.95), method = 6), 1)[[1]]
#paste0('DEATHS', ' : ', Td.death.obs, ' (', ci.death.low , ' - ', ci.death.upp , ')')


Td.report<- rbind(Td.report, 
                  data.frame(variable = 'Scotland death',
                       Td.obs = Td.death.obs,
                       ci.low = ci.death.low, ci.upp = ci.death.upp,
                       t1 = t1, t2 = t2))

```
 
```{r UK_DATA}

regions<- colnames(d.uk)[-1]


for(r in 1:length(regions)){
  
  d.clean<- # For focal uk region
    d.uk[,c(1, which(colnames(d.uk) == regions[r]))] %>%
    rename(cumNumCases = paste(regions[r])) %>%
    as.data.frame()
  
  
  d.clean.sim<- sim.epi(d.clean, its = its, plotsim = FALSE) # Simulate poisson error on raw cases
  
  d.clean.sim.norm<-
    d.clean.sim %>%
    select(-date, -cumNumCases) %>%
    mutate_all(~ cumsum(.) * (10000/(pops.uk[pops.uk$region == regions[r],'popsize']))) %>%
    rename(cumNumCases = numNewCases) %>%
    cbind(date = d.clean.sim$date) %>%
    select(c(ncol(.), seq(1, ncol(.)-1)))
  
  
  t2<- tail(tail(d.clean.sim.norm$date, 8), 1) # t2: latest date
  t1<- head(tail(d.clean.sim.norm$date, 8), 1) # t1: t2 - 7 available time steps
  
  
  d.clean.sim.norm.list<- # Apply compute.td.m1.v2 on each dataset (via sapply)
    d.clean.sim.norm %>%
    select(-date) %>%
    as.list()
  
  Tds<- sapply(d.clean.sim.norm.list, Td.lapply, dates = d.clean.sim.norm$date, t1 = t1, t2 = t2)
  
  # Observed and bootstrap distribution of Tds
  Td.obs<- as.numeric(Tds['cumNumCases'])
  Td.bootstrap<- as.numeric(Tds[-which(names(Tds) == 'cumNumCases')])
  Td.bootstrap<- Td.bootstrap[!is.na(Td.bootstrap == TRUE)] # NAs come from cases where there were still zero cases observed at t1 in a simulated dataset. Normal to happen when still very low number of cases observed. Becomes less of a problem as number of cases rise.
  
  # Get CI from distribution of Td
  ci.low<- round(quantile(Td.bootstrap, c(0.05), method = 6), 1)[[1]]
  ci.upp<- round(quantile(Td.bootstrap, c(0.95), method = 6), 1)[[1]]
  
  #print(paste0(regions[r], ' : ', Td.obs, ' (', ci.low , ' - ', ci.upp , ')'))
  
  Td.report<- rbind(Td.report,
                    data.frame(variable = paste(regions[r], 'cases'),
                               Td.obs = Td.obs[[1]],
                               ci.low = ci.low,
                               ci.upp = ci.upp,
                               t1 = t1,
                               t2 = t2)
  )
  
} 

t1.f2 = t1
t2.f2 = t2

```

```{r SCOTLAND_DATA}

regions<- colnames(d.cases)[-1]

sims.store<- vector('list',
                    length = length(regions))

for(r in 1:length(regions)){
  
  d<- # For focal health board. Additional step, going back to numNewCases to pass this through data.cleaner() function which applies the smoothing over the cases with negative numbers.
    d.cases[,c(1, which(colnames(d.cases) == regions[r]))] %>%
    rename(cumNumCases = paste(regions[r])) %>%
    mutate(numNewCases = c(cumNumCases[1], diff(cumNumCases))) %>%
    select(date, numNewCases)
  
  d.clean <- # Pass data through cleaner
    data.cleaner(d) %>%
    mutate(cumNumCases = cumsum(numNewCases)) %>%
    select(date, cumNumCases)
  
  
  d.clean.sim<- sim.epi(d.clean, its = its, plotsim = FALSE) # Simulate poisson error on raw cases
  
  d.clean.sim.norm<-
    d.clean.sim %>%
    select(-date, -cumNumCases) %>%
    mutate_all(~ cumsum(.) * (10000/(pops.shb[pops.shb$Health_board == regions[r],'popsize']))) %>%
    rename(cumNumCases = numNewCases) %>%
    cbind(date = d.clean.sim$date) %>%
    select(c(ncol(.), seq(1, ncol(.)-1)))
  
  names(sims.store)[r]<- regions[r]
  sims.store[[r]]<- d.clean.sim.norm
  
  t2<- tail(tail(d.clean.sim.norm$date, 8), 1) # t2: latest date
  t1<- head(tail(d.clean.sim.norm$date, 8), 1) # t1: t2 - 7 available time steps
  
  
  d.clean.sim.norm.list<- # Apply compute.td.m1.v2 on each dataset (via sapply)
    d.clean.sim.norm %>%
    select(-date) %>%
    as.list()
  
  Tds<- sapply(d.clean.sim.norm.list, Td.lapply, dates = d.clean.sim.norm$date, t1 = t1, t2 = t2)
  
  # Observed and bootstrap distribution of Tds
  Td.obs<- as.numeric(Tds['cumNumCases'])
  Td.bootstrap<- as.numeric(Tds[-which(names(Tds) == 'cumNumCases')])
  Td.bootstrap<- Td.bootstrap[!is.na(Td.bootstrap == TRUE)] # NAs come from cases where there were still zero cases observed at t1 in a simulated dataset. Normal to happen when still very low number of cases observed. Becomes less of a problem as number of cases rise.
  
  # Get CI from distribution of Td
  ci.low<- round(quantile(Td.bootstrap, c(0.05), method = 6), 1)[[1]]
  ci.upp<- round(quantile(Td.bootstrap, c(0.95), method = 6), 1)[[1]]
  
  #print(paste0(regions[r], ' : ', Td.obs, ' (', ci.low , ' - ', ci.upp , ')'))
  
  Td.report<- rbind(Td.report,
                    data.frame(variable = paste(regions[r], 'cases'),
                               Td.obs = Td.obs[[1]],
                               ci.low = ci.low,
                               ci.upp = ci.upp,
                               t1 = t1,
                               t2 = t2)
  )
  
} 

cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7", 'red', 'green', 'gold', 'cyan')


df.fig3<-
  d.cases %>%
  gather('Health_board', 'cumcases', 2:ncol(d.cases)) %>%
  left_join(pops.shb, by = 'Health_board') %>%
  mutate(cumcases_10k = cumcases * (10000/popsize))


t1.f3 = t1
t2.f3 = t2

```

```{r DAYS_BEHIND}

test<- d.uk %>%
  gather('region', 'cumCases', 2:4) %>%
  left_join(pops.uk, by = 'region') %>%
  mutate(cumCases10k = cumCases * (100000/popsize)) %>%
  select(-cumCases, -popsize) %>%
  spread('region', 'cumCases10k')


Scotland_vs_London<- epidemic.diff(test, 'Scotland', 'London')
Scotland_vs_rUKxL<- epidemic.diff(test, 'Scotland', 'Rest of UK')

text.Scotland_vs_London<- ifelse(Scotland_vs_London > 0, 'ahead', 'behind')
text.Scotland_vs_rUKxL<- ifelse(Scotland_vs_rUKxL > 0, 'ahead', 'behind')

```

```{r NEED_FOR_TEXT}

Td.report.analyses<- Td.report

Td.report$Td.obs<- formatC(Td.report$Td.obs, digits = 1, format = "f")
Td.report$ci.low<- formatC(Td.report$ci.low, digits = 1, format = "f")
Td.report$ci.upp<- formatC(Td.report$ci.upp, digits = 1, format = "f")


df.fig3b<-
  d.cases %>%
  gather('Health_board', 'cumcases', 2:ncol(d.cases)) %>%
  left_join(pops.shb, by = 'Health_board') %>%
  mutate(cumcases_10k = cumcases * (10000/popsize))%>%
  filter(cumcases_10k > 0) %>%
  select(date, Health_board,cumcases_10k) %>%
  spread(Health_board,cumcases_10k)

```
# Key points summary

We compare the size and rate of increase of the COVID-19 epidemic for Scotland, London and the rest of the UK except for London (rUKxL).  
&nbsp;
 
**The epidemic in Scotland is ~`r abs(round(Scotland_vs_London, 0))` days `r text.Scotland_vs_London` London and is now growing at a faster rate.**  

&nbsp;
 
Based on deaths:  
&nbsp;
 
* The current doubling time for deaths in Scotland is `r Td.report[Td.report$variable == 'Scotland death','Td.obs']` days (95% confidence interval: `r Td.report[Td.report$variable == 'Scotland death','ci.low']` - `r Td.report[Td.report$variable == 'Scotland death','ci.upp']` days) (Figure 1).  
* This is not significantly different from doubling time for previous 7 days (2.4 days; 95%CI: 1.6-3.7 days).  
&nbsp;
 
Based on case counts per 10,000 population available as of `r format(today, "%d/%m/%Y")`:  
&nbsp;
 
* The epidemic in Scotland is `r abs(Scotland_vs_London)` days `r text.Scotland_vs_London`  London and `r abs(Scotland_vs_rUKxL)` days `r text.Scotland_vs_rUKxL` of rUKxL (Figure 2).  
* The current 7-day doubling time in Scotland is `r Td.report[Td.report$variable == 'Scotland cases','Td.obs']` days (95%CI: `r Td.report[Td.report$variable == 'Scotland cases','ci.low']` - `r Td.report[Td.report$variable == 'Scotland cases','ci.upp']` days).  
* This is very similar to the doubling time for previous 7 days (4.2 days; 95%CI: 3.9-4.5 days).  
* The current doubling time in Scotland is significantly faster than London  (`r Td.report[Td.report$variable == 'London cases','Td.obs']` days, 95%CI: `r Td.report[Td.report$variable == 'London cases','ci.low']` - `r Td.report[Td.report$variable == 'London cases','ci.upp']` days) and significantly slower than rUKxL (`r Td.report[Td.report$variable == 'Rest of UK cases','Td.obs']` days, 95%CI: `r Td.report[Td.report$variable == 'Rest of UK cases','ci.low']` - `r Td.report[Td.report$variable == 'Rest of UK cases','ci.upp']` days) over the same time period.  
* Across Health Boards in Scotland there is variation in cumulative case incidence (`r round(min(tail(df.fig3b, 1)[,-1]), 1)` to `r round(max(tail(df.fig3b, 1)[,-1]), 1)` per 10,000 population, Figures 3, 4) and doubling time (`r min(Td.report$Td.obs)` to `r max(Td.report$Td.obs)` days, Figure 5).  
  
# Results

```{r fig1, fig.height = 6, fig.width = 6, fig.align = "center"}

yseq = seq(0, max(d.death.sim.2$cumNumCases) - (max(d.death.sim.2$cumNumCases) %% 10), 10)
xseq = seq.Date(from = min(d.death.sim.2$date), to = max(d.death.sim.2$date), by = 7)

inset.xmax.f1 = xseq[1] + (as.numeric(tail(xseq, 1) - head(xseq, 1)) * 0.45)
inset.text.adjust.x = xseq[1] + as.numeric(diff(range(xseq[1], inset.xmax.f1))) * 0
inset.text.adjust.y = tail(yseq, 2)[2] - as.numeric(diff(range(tail(yseq, 2)[1], tail(yseq, 2)[2]))) * c(0.2, 0.45)


# Draw plot and axes
plot(cumNumCases ~ date, data = d.death.sim.2, type = 'l', main = '  ',
     xlab = '', ylab = '', xaxt = 'n', yaxt = 'n')
mtext('Cumulative number of deaths', side = 2, font = 2, line = 2.2)
mtext('Date (dd/mm)', side = 1, font = 2, line = 2.5)
axis(2, at = yseq, labels = yseq, font = 2)
axis(1, at = xseq, labels = format(xseq, "%d/%m"), font = 2)

# Add shaded polygon on area over which Dt are calculated
polygon(x = c(t1.f1, t1.f1, t2.f1, t2.f1),
        #y = c(0, 3, 3, 0),
        y = c(0, d.death.sim.2[d.death.sim.2$date == t2,'cumNumCases'], d.death.sim.2[d.death.sim.2$date == t2,'cumNumCases'], 0),
        border = NA,
        col = adjustcolor('lightgrey', alpha = .4))

# Add background grids
abline(h = yseq, v = xseq, lty = 'dotted', col = 'lightgrey')

# Add legend
legend("topleft",
       legend = c("Doubling time (95%CI):",
                  paste('  ', Td.death.obs, ' (',ci.death.low, '-', ci.death.upp, ')')),
       #title = "Doubling time (95%CI):",
       col = 'black',
       #bty = 'n',
      # seg.len = 0.8,
      # x.intersp = 0,
       #text.width = 0.01,
       ncol = 1,
       title.adj = 0.4,
       y.intersp = 1,
       text.font = c(2,1),
      # lwd = 2,
       #lty = 1,
       inset=c(-0.05,-0.005))
box()

# Replot line on top to make it more visible
lines(cumNumCases ~ date, data = d.death.sim.2, lwd = 2)

```
**Figure 1. Epidemic curve for Scotland based on deaths over time up to `r format(today, "%d/%m/%Y")`.** Doubling time estimated over the past 7 days is 3.9 days (95%CI: 3.1-4.9 days).

&nbsp;


```{r fig2, fig.height = 6, fig.width = 12, fig.fullwidth = TRUE}

par(mfrow = c(1,2))

# FIG 2A ----
df.fig2A<-
  d.uk %>%
  rename(rUKxL = `Rest of UK`)

yseq = seq(0, max(df.fig2A[,2:4]) - max(df.fig2A[,2:4]) %% 2500, 2500)
xseq = seq.Date(from = min(df.fig2A$date), to = max(df.fig2A$date), by = 7)

inset.xmax.f2 = xseq[1] + (as.numeric(tail(xseq, 1) - head(xseq, 1)) * 0.6)
inset.ymax.f2 = max(df.fig2A[,2:4])
inset.text.adjust.x = xseq[1] + as.numeric(diff(range(xseq[1], inset.xmax.f2))) * 0
inset.text.adjust.y<- rev(seq(tail(yseq, 2)[2]*0.90, inset.ymax.f2, length.out = 4))


plot(rUKxL ~ date, data = df.fig2A, type = 'l', main = '  ',
     xlab = '', ylab = '', xaxt = 'n', yaxt = 'n', lwd = 2)
abline(h = yseq, v = xseq, col = 'lightgrey', lty = 'dotted')
lines(rUKxL ~ date, data = df.fig2A, lwd = 2, col = 'black')
lines(London ~ date, data = df.fig2A, lwd = 2, col = 'red')
lines(Scotland ~ date, data = df.fig2A, lwd = 2, col = 'dodgerblue')

mtext('Cumulative number of cases', side = 2, font = 2, line = 2.5, cex = 1.2)
mtext('Date (dd/mm)', side = 1, font = 2, line = 2.5, cex = 1.2)
axis(2, at = yseq, labels = yseq, font = 2, cex.axis = 1.2)
axis(1, at = xseq, labels = format(xseq, "%d/%m"), font = 2, cex.axis = 1.2)



mtext('A', side = 3, font = 2, line = 0.2, adj = 0, cex = 1.5)

polygon(x = c(xseq[1], xseq[1], inset.xmax.f2, inset.xmax.f2),
        y = c(inset.text.adjust.y[4], inset.ymax.f2, inset.ymax.f2, inset.text.adjust.y[4]),
        border = NA,
        col = adjustcolor('lightgrey', alpha = .2))


#inset.text.adjust.y = inset.ymax.f2 - as.numeric(diff(range(tail(yseq, 2)[1], tail(yseq, 2)[2]))) * c(0.25, 0.55, 0.85)

regions.y.pos = rev(seq(inset.text.adjust.y[4]+300, inset.text.adjust.y[1]-300, length.out = 4))


text(x = inset.text.adjust.x,
     y = regions.y.pos,
     lty = 2,
     labels = c('Region/Country:', ' rUKxL', ' London', ' Scotland'),
     col = c('black', 'black', 'red', 'dodgerblue'),
     pos = 4,
     font = c(2, rep(1, 11)),
     cex = 0.8)


# FIG 2B ----

df.fig2B<-
  d.uk %>%
  gather('region', 'cumcases', 2:4) %>%
  left_join(pops.uk, by = 'region') %>%
  mutate(cumcases_10k = cumcases * (10000/popsize)) %>%
  select(date, region, cumcases_10k) %>%
  spread(region, cumcases_10k) %>%
  rename(rUKxL = `Rest of UK`)


yseq = c(-1.5, -1, 0, 1, 1.5, 2)
xseq = seq.Date(from = min(df.fig2B$date), to = max(df.fig2B$date), by = 7)

inset.xmax.f2 = xseq[1] + (as.numeric(tail(xseq, 1) - head(xseq, 1)) * 0.7)
inset.ymax.f2 = max(df.fig2B[,2:4])
inset.text.adjust.x = xseq[1] + as.numeric(diff(range(xseq[1], inset.xmax.f2))) * 0
inset.text.adjust.y = c(1.82, 1.57, 1.32, 1.07)


plot(log10(London) ~ date, data = df.fig2B, type = 'l', main = '  ',
     xlab = '', ylab = '', xaxt = 'n', yaxt = 'n', lwd = 2, ylim = c(-1.5, 2))

polygon(x = c(t1.f2, t1.f2, t2.f2, t2.f2),
        y = c(-1.5, 2, 2, -1.5),
        border = NA,
        col = adjustcolor('lightgrey', alpha = .4))

polygon(x = c(xseq[1], xseq[1], inset.xmax.f2, inset.xmax.f2),
        y = c(1, 2, 2, 1),
        border = NA,
        col = adjustcolor('lightgrey', alpha = .2))

abline(h = yseq, v = xseq, col = 'lightgrey', lty = 'dotted')


lines(log10(rUKxL) ~ date, data = df.fig2B, lwd = 2, col = 'black')
lines(log10(London) ~ date, data = df.fig2B, lwd = 2, col = 'red')
lines(log10(Scotland) ~ date, data = df.fig2B, lwd = 2, col = 'dodgerblue')

mtext('Cumulative cases per 10k pop. (log10)', side = 2, font = 2, line = 2.5, cex = 1.2)
mtext('Date (dd/mm)', side = 1, font = 2, line = 2.5, cex = 1.2)
axis(2, at = yseq, labels = yseq, font = 2, cex.axis = 1.2)
axis(1, at = xseq, labels = format(xseq, "%d/%m"), font = 2, cex.axis = 1.2)

mtext('B', side = 3, font = 2, line = 0.2, adj = 0, cex = 1.5)

td.rUKxL = Td.report[Td.report$variable == 'Rest of UK cases', c('Td.obs', 'ci.low', 'ci.upp')]
td.london = Td.report[Td.report$variable == 'London cases', c('Td.obs', 'ci.low', 'ci.upp')]
td.scotland = Td.report[Td.report$variable == 'Scotland cases', c('Td.obs', 'ci.low', 'ci.upp')]

inset.td.rUKxL<- paste0(' rUKxL: ', td.rUKxL$Td.obs, ' (', td.rUKxL$ci.low , '-', td.rUKxL$ci.upp,')')
inset.td.london<- paste0(' London: ', td.london$Td.obs, ' (', td.london$ci.low , '-', td.london$ci.upp,')')
inset.td.scotland<- paste0(' Scotland: ', td.scotland$Td.obs, ' (', td.scotland$ci.low , '-', td.scotland$ci.upp,')')




text(x = inset.text.adjust.x,
     y = inset.text.adjust.y,
     labels = c('Doubling times (95%CI):', inset.td.rUKxL, inset.td.london, inset.td.scotland),
     col = c('black', 'black', 'red', 'dodgerblue'),
     pos = 4,
     font = c(2, rep(1, 11)),
     cex = 0.8)

```

**Figure 2. Comparison of epidemic curves for Scotland, London and rUKxL up to `r format(today, "%d/%m/%Y")`**. **A)** Cumulative reported cases. **B)** Cumulative cases per 10,000 population on a log10 scale. Inset shows corresponding doubling times (in days) over the past 7 days (with 95% confidence intervals).
&nbsp;
 

&nbsp;
 
&nbsp;
 
&nbsp;
 
 
```{r fig3, fig.height = 6, fig.width = 12, fig.fullwidth = TRUE}

td.Ayrshire = Td.report[Td.report$variable == 'Ayrshire cases', c('Td.obs', 'ci.low', 'ci.upp')]
td.Borders = Td.report[Td.report$variable == 'Borders cases', c('Td.obs', 'ci.low', 'ci.upp')]
td.Dumfries_and_Galloway = Td.report[Td.report$variable == 'Dumfries and Galloway cases', c('Td.obs', 'ci.low', 'ci.upp')]
td.Fife = Td.report[Td.report$variable == 'Fife cases', c('Td.obs', 'ci.low', 'ci.upp')]
td.Forth_Valley = Td.report[Td.report$variable == 'Forth Valley cases', c('Td.obs', 'ci.low', 'ci.upp')]
td.Grampian_Shetland_and_Orkney = Td.report[Td.report$variable == 'Grampian Shetland and Orkney cases', c('Td.obs', 'ci.low', 'ci.upp')]
td.Greater_Glasgow_and_Clyde = Td.report[Td.report$variable == 'Greater Glasgow and Clyde cases', c('Td.obs', 'ci.low', 'ci.upp')]
td.Highland_and_Western_Isles = Td.report[Td.report$variable == 'Highland and Western Isles cases', c('Td.obs', 'ci.low', 'ci.upp')]
td.Lanarkshire = Td.report[Td.report$variable == 'Lanarkshire cases', c('Td.obs', 'ci.low', 'ci.upp')]
td.Lothian = Td.report[Td.report$variable == 'Lothian cases', c('Td.obs', 'ci.low', 'ci.upp')]
td.Tayside = Td.report[Td.report$variable == 'Tayside cases', c('Td.obs', 'ci.low', 'ci.upp')]



# Used in both A and B (in A for HB names)
inset.td.Ayrshire<- paste0(' Ayrshire: ', td.Ayrshire$Td.obs, ' (', td.Ayrshire$ci.low , '-', td.Ayrshire$ci.upp,')')
inset.td.Borders<- paste0(' Borders: ', td.Borders$Td.obs, ' (', td.Borders$ci.low , '-', td.Borders$ci.upp,')')
inset.td.Dumfries_and_Galloway<- paste0(' Dumfries/Galloway: ', td.Ayrshire$Td.obs, ' (', td.Ayrshire$ci.low , '-', td.Ayrshire$ci.upp,')')
inset.td.Fife<- paste0(' Fife: ', td.Fife$Td.obs, ' (', td.Fife$ci.low , '-', td.Fife$ci.upp,')')
inset.td.Forth_Valley<- paste0(' Forth Valley: ', td.Forth_Valley$Td.obs, ' (', td.Forth_Valley$ci.low , '-', td.Forth_Valley$ci.upp,')')
inset.td.Grampian_Shetland_and_Orkney<- paste0(' Grampian, Shetland & Orkney: ', td.Grampian_Shetland_and_Orkney$Td.obs, ' (', td.Grampian_Shetland_and_Orkney$ci.low , '-', td.Grampian_Shetland_and_Orkney$ci.upp,')')
inset.td.Greater_Glasgow_and_Clyde<- paste0(' Glasgow & Clyde: ', td.Greater_Glasgow_and_Clyde$Td.obs, ' (', td.Greater_Glasgow_and_Clyde$ci.low , '-', td.Greater_Glasgow_and_Clyde$ci.upp,')')
inset.td.Highland_and_Western_Isles<- paste0(' Highland & W. Ilses: ', td.Highland_and_Western_Isles$Td.obs, ' (', td.Highland_and_Western_Isles$ci.low , '-', td.Highland_and_Western_Isles$ci.upp,')')
inset.td.Lanarkshire<- paste0(' Lanarkshire: ', td.Lanarkshire$Td.obs, ' (', td.Lanarkshire$ci.low , '-', td.Lanarkshire$ci.upp,')')
inset.td.Lothian<- paste0(' Lothian: ', td.Lothian$Td.obs, ' (', td.Lothian$ci.low , '-', td.Lothian$ci.upp,')')
inset.td.Tayside<- paste0(' Tayside: ', td.Tayside$Td.obs, ' (', td.Tayside$ci.low , '-', td.Tayside$ci.upp,')')

hb.names<- c(
inset.td.Grampian_Shetland_and_Orkney,
inset.td.Highland_and_Western_Isles,
inset.td.Dumfries_and_Galloway,
inset.td.Greater_Glasgow_and_Clyde,
inset.td.Lanarkshire,
inset.td.Forth_Valley,
inset.td.Tayside,
inset.td.Lothian,
inset.td.Borders,
inset.td.Ayrshire,
inset.td.Fife)

figb.lwd = 2

par(mfrow = c(1,2))


# FIG 3A ----

f3.ymax = max(d.cases[,2:ncol(d.cases)])
yseq = seq(0, f3.ymax - f3.ymax %% 100, 100)
xseq = seq.Date(from = min(d.cases$date), to = max(d.cases$date), by = 7)
inset.xmax.f3 = xseq[1] + (as.numeric(tail(xseq, 1) - head(xseq, 1)) * 0.5)
inset.ymax.f3 = f3.ymax

plot(Ayrshire ~ date, data = d.cases, type = 'l', main = '  ',
     xlab = '', ylab = '', xaxt = 'n', yaxt = 'n', lwd = 1,
     ylim = c(0, f3.ymax))

abline(h = yseq, v = xseq, col = 'lightgrey', lty = 'dotted')

polygon(x = c(xseq[1], xseq[1], inset.xmax.f3, inset.xmax.f3),
        y = c(tail(yseq, 2)[2]*0.5, inset.ymax.f3, inset.ymax.f3, tail(yseq, 2)[2]*0.5),
        border = NA,
        col = adjustcolor('lightgrey', alpha = .2))

lines(Ayrshire ~ date, data = d.cases, lwd = figb.lwd, col = '#88CCEE')
lines(Borders ~ date, data = d.cases, lwd = figb.lwd, col = '#CC6677')
lines(`Dumfries and Galloway` ~ date, data = d.cases, lwd = figb.lwd, col = '#DDCC77')
lines(Fife ~ date, data = d.cases, lwd = figb.lwd, col = '#117733')
lines(`Forth Valley` ~ date, data = d.cases, lwd = figb.lwd, col = '#332288')
lines(`Grampian Shetland and Orkney` ~ date, data = d.cases, lwd = figb.lwd, col = '#AA4499')
lines(`Greater Glasgow and Clyde` ~ date, data = d.cases, lwd = figb.lwd, col = '#44AA99')
lines(`Highland and Western Isles` ~ date, data = d.cases, lwd = figb.lwd, col = '#999933')
lines(Lanarkshire ~ date, data = d.cases, lwd = figb.lwd, col = '#882255')
lines(Lothian ~ date, data = d.cases, lwd = figb.lwd, col = '#661100')
lines(Tayside ~ date, data = d.cases, lwd = figb.lwd, col = '#888888')


mtext('Cumulative number of cases', side = 2, font = 2, line = 2.5, cex = 1.2)
mtext('Date (dd/mm)', side = 1, font = 2, line = 2.5, cex = 1.2)
axis(2, at = yseq, labels = yseq, font = 2, cex.axis = 1.2)
axis(1, at = xseq, labels = format(xseq, "%d/%m"), font = 2, cex.axis = 1.2)

mtext('A', side = 3, font = 2, line = 0.2, adj = 0, cex = 1.5)



inset.text.adjust.x = xseq[1] + as.numeric(diff(range(xseq[1], inset.xmax.f2))) * 0
#inset.hb.y.pos<- tail(yseq, 1) * rev(seq(0.45, 0.95, length.out = 12))
inset.hb.y.pos.f3a<- rev(seq(310, 620, length.out = 12))


hb.names.a<- do.call('rbind', strsplit(hb.names, ':'))[,1]

cols.f3a<- c("#AA4499","#999933", "#DDCC77","#44AA99", "#882255", "#332288", "#888888",
             "#661100", "#CC6677", "#88CCEE", "#117733")

text(x = inset.text.adjust.x,
     y = inset.hb.y.pos.f3a,
     #lty = 2,
     labels = c('Health board:', hb.names.a),
     col = c('black',cols.f3a),
     pos = 4,
     font = c(2, rep(1, 11)),
     cex = 0.8)


# FIG 3B ----

f3b.ymax = max(log10(df.fig3b[,2:ncol(df.fig3b)]), na.rm = TRUE)
yseq = c(-2, -1, 0, 1, 2)
xseq = seq.Date(from = min(df.fig3b$date), to = max(df.fig3b$date), by = 7)
inset.xmax.f3 = xseq[1] + (as.numeric(tail(xseq, 1) - head(xseq, 1)) * 0.75)
inset.ymax.f3 = f3b.ymax

plot(log10(Ayrshire) ~ date, data = df.fig3b, type = 'l', main = '  ',
     xlab = '', ylab = '', xaxt = 'n', yaxt = 'n', lwd = 1,
     ylim = c(-2, 1))

polygon(x = c(t1.f3, t1.f3, t2.f3, t2.f3),
        y = c(-2, 1, 1, -2),
        border = NA,
        col = adjustcolor('lightgrey', alpha = .4))

abline(h = yseq, v = xseq, col = 'lightgrey', lty = 'dotted')

polygon(x = c(xseq[1], xseq[1], inset.xmax.f3, inset.xmax.f3),
        y = c(-0.55, 1, 1, -0.55),
        border = NA,
        col = adjustcolor('lightgrey', alpha = .2))


lines(log10(Ayrshire) ~ date, data = df.fig3b, lwd = figb.lwd, col = '#88CCEE')
lines(log10(Borders) ~ date, data = df.fig3b, lwd = figb.lwd, col = '#CC6677')
lines(log10(`Dumfries and Galloway`) ~ date, data = df.fig3b, lwd = figb.lwd, col = '#DDCC77')
lines(log10(Fife) ~ date, data = df.fig3b, lwd = figb.lwd, col = '#117733')
lines(log10(`Forth Valley`) ~ date, data = df.fig3b, lwd = figb.lwd, col = '#332288')
lines(log10(`Grampian Shetland and Orkney`) ~ date, data = df.fig3b, lwd = figb.lwd, col = '#AA4499')
lines(log10(`Greater Glasgow and Clyde`) ~ date, data = df.fig3b, lwd = figb.lwd, col = '#44AA99')
lines(log10(`Highland and Western Isles`) ~ date, data = df.fig3b, lwd = figb.lwd, col = '#999933')
lines(log10(Lanarkshire) ~ date, data = df.fig3b, lwd = figb.lwd, col = '#882255')
lines(log10(Lothian) ~ date, data = df.fig3b, lwd = figb.lwd, col = '#661100')
lines(log10(Tayside) ~ date, data = df.fig3b, lwd = figb.lwd, col = '#888888')

mtext('Cumulative cases per 10k pop. (log10)', side = 2, font = 2, line = 2.5, cex = 1.2)
mtext('Date (dd/mm)', side = 1, font = 2, line = 2.5, cex = 1.2)
axis(2, at = yseq, labels = yseq, font = 2, cex.axis = 1.2)
axis(1, at = xseq, labels = format(xseq, "%d/%m"), font = 2, cex.axis = 1.2)
mtext('B', side = 3, font = 2, line = 0.2, adj = 0, cex = 1.5)



inset.hb.y.pos.f3b<- rev(seq(-0.5, 0.9, length.out = 12))


text(x = inset.text.adjust.x,
     y = inset.hb.y.pos.f3b,
     #lty = 2,
     labels = c('Doubling times (95%CI):', hb.names),
     col = c('black',cols.f3a),
     pos = 4,
     font = c(2, rep(1, 11)),
     cex = 0.8)



```
&nbsp;

**Figure 3. Comparison of epidemic curves for all Scottish Health Boards up to `r format(today, "%d/%m/%Y")`**. **A)** Cumulative reported cases. **B)** Cumulative cases per 10,000 population on log10 scale. Inset shows corresponding doubling times (in days) estimated over the past 7 days with 95% confidence intervals.

\newpage

```{r, fig.height = 7.5, fig.width = 10, fig.align = "center", warning = FALSE}

dat.hist.cumsum10k<- vector('list', length = length(regions))

for(i in 1:length(sims.store)){
 
latest<- sims.store[[i]] %>%
  mutate(region = names(sims.store[i])) %>%
  rename(cumNumCase_10k = cumNumCases) %>%
  tail(., 1)


cumNumCases_10k.sim.last<- as.numeric(latest[,which(substr(colnames(latest), 1, 1) == 'V')])

ci.low.cumNumCases_10k<- round(quantile(cumNumCases_10k.sim.last, c(0.05), method = 6), 1)[[1]]
ci.upp.cumNumCases_10k<- round(quantile(cumNumCases_10k.sim.last, c(0.95), method = 6), 1)[[1]]

dat.hist.cumsum10k[[i]]<-
latest %>%
  select(date, region, cumNumCase_10k) %>%
  mutate(ci.low = ci.low.cumNumCases_10k,
         ci.upp = ci.upp.cumNumCases_10k)
}

df.hist.cumsum10k<- do.call('rbind', dat.hist.cumsum10k)

df.hist.cumsum10k$region[which(df.hist.cumsum10k$region == "Grampian Shetland and Orkney")]<- "Grampian, Shetland and Orkney"

df.hist.cumsum10k$region<- factor(df.hist.cumsum10k$region, levels = df.hist.cumsum10k$region[rev(order(df.hist.cumsum10k$cumNumCase_10k))])


ggplot(df.hist.cumsum10k, aes(x = region, y = cumNumCase_10k))+
  geom_histogram(stat = 'identity', width = 0.8, color = "black", fill = 'gray45')+
  geom_errorbar(aes(ymin = ci.low, ymax = ci.upp), width = 0.20, lwd = 1)+
  xlab('Health board') + ylab('Cumulative reported cases per 10k pop.\n ')+
  theme_bw()+
  theme(legend.position="none",
        panel.border= element_blank(),
        axis.text.y = element_text(face="bold", colour="black", size=16),
        axis.text.x = element_text(colour="black", face="bold", size=14, angle = 45, vjust=1, hjust=1),
        axis.title.y = element_text(face="bold", colour="black", size=15),
        axis.title.x = element_text(face="bold", colour="black", size=15),
        axis.line.y = element_line(color="black", size = 0.5),
        axis.line.x = element_line(color="black", size = 0.5),
        plot.title = element_text(lineheight=.8, face="bold", hjust = 0.5),
        panel.grid.major = element_line(color = 'grey', linetype = 'dotted'))



```
&nbsp;

**Figure 4. Cumulative incidence for all Scottish Health Boards up to `r format(today, "%d/%m/%Y")`**. The error bars show the 95%CI of the cumulative incidence per 10,000 population reached at last time point over the bootstrapped simulated datasets with Poisson error structure.

\newpage

```{r, fig.height = 7, fig.width = 9, fig.align = "center", warning = FALSE}


Td.report.analyses.clean<- 
  Td.report.analyses %>%
  rename(`Country/Health board` = variable,
         Dt = Td.obs) %>%
  select(`Country/Health board`, Dt, ci.low, ci.upp)


Td.report.analyses.clean.hb<- Td.report.analyses.clean[-c(1:4),] %>%
  arrange(-Dt)


xseq.min<- floor(-range(Td.report.analyses.clean.hb[,2:4])[c(2)])
xseq.max<- ceiling(-range(Td.report.analyses.clean.hb[,2:4])[c(1)])
xseq<- seq(xseq.min, xseq.max, by = 1)

par(mar = c(4, 15, 2, 1))

plot('', xlim = range(xseq), ylim = c(0, nrow(Td.report.analyses.clean.hb)+1),
     xaxt = 'n', yaxt = 'n', xlab = '', ylab = '')

axis(1, at = xseq, labels = abs(xseq), font = 2, cex.axis = 1.2)

hb.names<- str_replace(as.character(Td.report.analyses.clean.hb$`Country/Health board`), ' cases', '')

hb.names[which(hb.names == "Grampian Shetland and Orkney")]<- "Grampian, Shetland and Orkney"

ytick<- seq(1, nrow(Td.report.analyses.clean.hb), 1)
axis(side=2, at=ytick, labels = FALSE, tick = TRUE)
text(par("usr")[1], ytick,  
     labels = hb.names, offset = 1, pos = 2, xpd = TRUE, font = 2, cex = 1)

mtext('Doubling time (days)', side = 1, font = 2, line = 2.5)

for(x in 1:(length(xseq)-1)){
 
xseq.focal<- xseq[c(x, length(xseq))]

polygon(x = rep(xseq.focal, each = 2),
        y = c(0, nrow(Td.report.analyses.clean.hb)+1, nrow(Td.report.analyses.clean.hb)+1, 0),
        border = 'NA',
        col = adjustcolor('firebrick', alpha = .1))
}


for(c in 1:nrow(Td.report.analyses.clean.hb)){
  points(x = -Td.report.analyses.clean.hb$Dt[c], y = c, pch = 16, cex = 1.3)
  lines(y = c(c,c), x = -Td.report.analyses.clean.hb[c,c('ci.low', 'ci.upp')], lwd = 3)
  lines(y = c(c+0.1, c-0.1), x = -rep(Td.report.analyses.clean.hb$ci.low[c], 2), lwd = 3)
  lines(y = c(c+0.1, c-0.1), x = -rep(Td.report.analyses.clean.hb$ci.upp[c], 2), lwd = 3)
}

```
&nbsp;

**Figure 5. Doubling time of cases**. Doubling times are calculated over a 7 day period up to `r format(today, "%d/%m/%Y")` Error bars indicate 95%CI.

\newpage

# Data

- Case counts for Scotland and for Scottish HBs from https://www.gov.scot/coronavirus-covid-19/ (accessed 1200 `r format(today, "%d/%m/%Y")`).  
- Case counts for London and rUK except London from https://www.arcgis.com/apps/opsdashboard/index.html#/f94c3c90da5b4e9f9a0b19484dd4bb14 (accessed 2000 `r format(today, "%d/%m/%Y")`).  
- Death count for Scotland from https://www.gov.scot/coronavirus-covid-19/ (accessed 1200 `r format(today, "%d/%m/%Y")`).  
- Population counts from the Office of National Statistics (mid-year 2018).
    - UK:  https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/populationestimates/datasets/populationestimatesforukenglandandwalesscotlandandnorthernireland, Mid-2018, spreadsheet 'MYE2-all' (accessed 1140 26/03/20) 
    - Scotland Health Board Areas:   https://statistics.gov.scot/atlas/resource?uri=http://statistics.gov.scot/id/statistical-geography/S92000003 (accessed 1200 11/03/20). 

# Doubling time calculations:

Calculated over prior 7 days using method described by *E. Vynnycky & R. White (2010) An Introduction to Infectious Disease Modelling*, page 74.  
  
Confidence intervals calculated using bootstrapping of a simulated dataset with Poisson error structure, using method published here: https://doi.org/10.1101/2020.02.05.20020750.  


# Caveats
* Case count data are affected by any changes in testing strategy or testing effort over time and/or any variation in testing strategy or testing effort between regions.  
* Case count data are likely a substantial under-representation of the true number of COVID-19 infections.  
* Death data are considered more reliable but may lag behind case data by as much as 3 weeks.  
* However, death data for London and rUKxL cannot be disaggregated. Nor can death data for Scottish Health Boards. Therefore more detailed analyses using death data are not currently possible.  
